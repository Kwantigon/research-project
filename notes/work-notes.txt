V property summary bude jednodušší, když vyjmenuju všechny properties, které by uživatele mohlo zajímat.
Uživatel pak může vybírat v tom seznamu.
Je to jednodušší než nechat uživatele klikat přímo do summary.

Když si uživatel zvolí, že chce použít nějaké property pro expanzi, tak jakou metodou to poslat na server? A na jaký endpoint?

Idea je, že na serveru si stavím tu další otázku uživatele, ale ještě ji necommitnu do konverzace. Když si uživatel zvolí propertu, tak se přidá do té další otázky. Když uživatel pošle samotnou zprávu, kterou jsme spolu sestavili, tak BE opravdu přidá tu otázku do konverzace.
- Jak zpracovat tu další otázku? Určitě ne stejným způsobem jako první otázka.
- Přidat si ty zvolené properties do podstruktury, kterou stavím na back endu.
- Nechat si přeložit tu podstrukturu do Sparqlu.
- Říct LLM, aby mi dalo nějaké rozumné další properties?
FE: POST question-preview + 1 property.
BE: Přidá property do substructure preview + řekne LLM, aby lexikalizoval.
FE: GET question-preview.
BE: Vrátí lexikalizaci.
FE: PUT question-preview + 1 property?
Request na question-preview by možná vždycky měl obsahovat všechny properties, které uživatel tam chce. Tím umožním i to, že když uživatel chce odebrat property, tak stačí poslat PUT request s příslušnými parametry a BE vytvoří správné preview?
- Takže správný HTTP verb bude PUT.
FE si musí držet seznam properties, které si uživatel vybral.

Back end si udržuje stav konverzace.
2 možnosti, jak uživatel může zadat svůj follow-up otázku.
- Ručně napíše.
- Vybírá si properties a pak potvrdí.
- To by trochu zjednodušilo zpracování na back endu, když přijde zpráva.
- Pokud uživatel potvrdil, na back endu můžu jen potvrdit question preview.
- Pokud uživatel zadal ručně otázku, možná budu muset zpracovat jako první dotaz.

Konkrétní data v databázi nemám, ale možná bych mohl použít LLM, abych mohl doplnit do dotazu to, co uživatel chce.
Například chce: Tournaments that have taken place this year so far in which there are participants *from Vietnam*.
- Já dokážu vyznačit to, že dotaz se bude týkat tournament a player a country.
- Tak teď nějakým způsobem říct LLM, kam by měl uživatel doplnit specifické hodnoty, které chce ve svém dotazu mít - např. Vietnam.

*20/04/2025*
Jak píšu tu mock konverzaci, tak se mi zdá, že pořád bude lepší mít jen seznam namapovaných slov. Potom ty související itemy zobrazit až když uživatel si rozklikne to slovo.
- A nebo to nechat jako seznam, ale vhodně odrazit.
- Když item patří třeba do tournaments, tak vylistovat hned pod tournaments a ještě odrazit.
- JAJA to zní dobře.
Nevýhoda tohoto přístupu je, že se musím zastavit po nějakém stupni zanoření. Když to zobrazím v separátním oknu, tak teoreticky uživatel může klikat a jít do jakékoliv hloubky.

Major části, které musím nastudovat a implementovat.
1. Co poslat do LLM a jak promptovat, abych získal výstup, který potřebuju.
	3.a) Musím si vytvořit nějaký Dataspecer package. Nebo použít již existující.
	3.b) Musím získat přístup na náš LLM server - napsat do chatu.
2. Co si vytáhnout z toho Dataspecer package pro zpracování.
	- Vyřeším, pokud udělám krok 1.
3. Jak stáhnout Dataspecer package v kódu.
	- Poradit se se Štěpánem.
4. Přidat databázi.
	4.a) Podívat se na Entity Framework guide.
	4.b) Rozběhnout Sqlite nebo Postgres.
5. Nastudovat, jak převést data specification substructure na Sparql query (pro implementaci Sparql translation service).
6. Implementovat front end.

26/04/2025
Když si exportuju specifikaci z Dataspeceru, tak tam je .owl.ttl soubor, což je RDF.

Když mám data jako RDF, tak to je vždycky node, šipka a další node ne? Takže můžu teoreticky reprezentovat tady ty 2 věci v kódu?
- Určitě můžu uložit typ class.
- Určitě můžu uložit typ relationship.
- Myslím si, že typ property můžu taky.
Když se zeptám na summary RDF, tak mi LLAMA popíše class, property a relationship. Takže tady ty 3 věci budou items.

Když řeknu "summarize class ...", tak to popíše to, co je napsaný v tom RDF. Já si pod "summarize" představuju spíše kousek textu, který je srozumitelný pro netechnického člověka.

Please summarize the class "barrier-free access" in a few sentences so that a non-technical person can understand it.
The "Barrier-Free Access" class refers to information about how easily people with disabilities can access and use a particular location, such as a building or tourist destination. It describes the
accessibility features of the location from the user's point of view. This class is used to provide details about the accessibility of a place, which can be helpful for people who need to plan their
visits accordingly.
- Toto už je trochu lepší, ale je dost možné, že si bude domýšlet. Ale to asi nevadí, protože bych chtěl, aby z kontextu té datové specifikace udělal to shrnutí.

Data specification:
- Určitě si uložím RDF string.
- Uložím si items. Ale pokud je datová specifikace velká, tak asi nemůžu uložit všechno ne?
- Ještě bych si mohl uložit další věci jako datové struktury atd. Prostě kontext kolem toho.
Data specification item:
- Uložím si typ (class, property, relationship).
- Summary (některé si už můžu předem vygenerovat).

*02/05/2025*
Pořád řeším, jak rozdělit zpracování endpointů.
- Mít jeden controller.
- Nebo mít různé controllery pro každé endpointy.
Do specifikace jsem napsal, že request handler deleguje práci do ostatních modulů.

Myslím si, že dává smysl, že Program.cs mapuje endpoint. Nějaký controller bude volat metody na conversation service a případně jiných servisech. Pak ten výsledek přetransformuje do vhodné HTTP formy.
- Např. na některé věci bude volat IConversationService. Ale pak vrátí jen 201_Created nebo něco takového.
- To nedává smysl vracet z IConversationService.

Co vše musím udělat, abych měl funkční back end?
- Zpracovat Dataspecer package (DSL do OWL a pak uložit jako string).
- Přidat Entity Framework.
- Implementovat komunikaci s Ollama.
- Přidat potřebné metody do interface servisů v core.

Mapuju endpointy a podle těch endpointů definuju metody, které musejí servisy podporovat.

Přemýšlím, co si uložit pod datovou specifikaci. Jestli všechny její třídy a property.
- To může teoreticky být hodně.
- Stejně vždycky dávám tu specifikaci jako RDF do LLM.
- Takže si jen uložím ten OWL.
Jako podstrukturu si uložím prostě seznam itemů.
- K tomu ještě třeba suggested message.

Napadlo mě, jestli reprezentace datové specifikace může mít vliv na výsledný query podle jazyku.
- Např. já chci na výstupu vydat Sparql, tak možná reprezentovat datovou specifikaci jako RDF bude lepší než reprezentovat jako něco jiného.
- Kdybych chtěl SQL query, tak možná RDF bude mít horší performance.

Kde jsem skončil:
- Přidal jsem metodu AddUserMessage.
- Musím přidat zpracování, které bere v úvahu RDF itemy.

Teď musím pracovat na tom, jak vytvořit vstupní OWL pro LLM.
- Nebo možná markdown bude lepší tvar.
- Každopádně musím zpracovat OWL.TTL a DSV.TTL a ještě odkazy v nich. Pak si ty informace zpracuju do nějakého tvaru.
Musím se podívat do dokumentace Dataspeceru, abych viděl popis RDF a aplikačních profilů atd.

V Class mi zatím chybí rdfs:label a rdfs:comment. To musím vyřešit tak, že to vytáhnu z reusesPropertyValue.
Pro získání věcí v reusesPropertyValue budu podporovat následující formáty dat:
- Turtle
- N-triples
- JSON-LD
- RDF/XML
- RDF/JSON
- Zeptám se na konzultaci, jaké další formáty bych měl podporovat.
Musím nějak získat URI, které vede přímo na to RDF a to můžu předat přímo do dotnetRDF pro načtení grafu.
slovník.gov.cz má ti URIčka úplně dole a ty odkazy vedou na dokumenty, které potřebuju. Ale je problém nějak vůbec získat to URI ... použít LLM?

Myslím si, že prozatím tam implementuju jen primitivní zpracování - prostě se pokusím otevřít ten odkaz v dsv:ReusedFromProperty a získat hodnotu. Pokud to neloadne RDF graf, tak prostě pokračuju bez toho.
Refaktoruju kód ve třídě DataSpecificationService, aby všechno nebylo v jedné metodě.

Otázky:
- Fasáda: dává smysl celou metodu pro konverzi dát do fasády nebo je lepší to zpracování mít v DataSpecificationService a detailní volání nějakých dotnetRdf metod dát do fasády?

## 22. 6. 2025

Minule jsem začal přesouvat komplikované zpracování s dotnetRDF do fasády. Není to ještě hotové, ale prozatím toho nechám.

Chtěl bych "zprovoznit" ten back end. Fasáda nemá úplně vliv na to, jestli back end bude něco vracet nebo zpracovávat, takže to nechám na později.

Dívám se na to, co posílal Štěpán a zkusím vymyslet, jak z toho získat DSV.

Dataspecer používá pro každý package nějaké UUID, kterému říká IRI a je to vidět v odkazech třeba na dokumentaci.

V tuto chvíli je mi teoreticky jedno, v jakém formátu Dataspecer vrací data. Jestli json-ld nebo dsv nebo owl. Já potřebuju něco, co nacpu do LLM, abych měl první funkční implementaci.
- Takže teď to nebudu podrobně zkoumat a implementuju prostě něco. Klidně třeba přímo to json-ld.
- Pak se uvidí.

Nejdřív to zkusím zprovoznit, protože musím se ještě napojit na ollama a vymyslet pár promptů. A pak zpracování těch promptů.

Získání json-ld dokumentaci prozatím funguje.
Teď musím implementovat ten workflow té konverzace.

Napadlo mě, že bych mohl zkusit použít HttpClient a přímo stáhnout dokumentaci package z Dataspeceru.
- Zkusil jsem to implementovat a vypadá to, že to funguje.

Napadlo mě, že nemusím ukládat stažený ZIP, ale stačí otevřít přímo z toho byte array.
Dále přidat interface PromptConstructor a ResponseProcessor do interface LlmConnector.

## 20. 7.

Třídy ve složce Model už mám asi v pohodě pro entity framework. Teď začnu nahrazovat mocky.
Dataspecer connector hází chyby.
- Jeden package nelze vůbec stáhnout.
- Jiný package asi zase má divný formát Turtlu.
- Budu to muset probrat se Štěpánem.

Když namockuju konektor, tak konverzaci už vytvořím v pohodě.
Zprávy taky dokážu vytáhnout z databáze a vrátit.

Teď musím implementovat samotné zpracování nových zpráv.

Musím taky přidat podporu pro suggested message do front endu.

## 25. 7.

Generování odpovědi jsem dal do volání GET /.../{messageId}, což není úplně nejlepší.
GET by neměl spouštět nějaké zdlouhavé procesy na back endu.
Měl bych to pustit už při POST user message.
Pak front end bude prostě čekat na odpověď opakovaným voláním GET?
- Na druhou stranu, když zajistím, že ta operace je idempotentní (nebo jak se tomu říká), tak by to mohlo být v pohodě.
- Jen první GET request spustí generování odpovědi.
- Další requesty už jen čekají a pokud uvidí, že odpověď je vygenerovaný, tak vrátí.
- Ale problém je, že když není zavolán GET, tak se mi to nezačne generovat.
- Ale to je asi v pořádku. Když nikdo nevolá GET, tak asi nikdo nechce tu odpověď.

Musím vyřešit synchronizaci, aby se nestalo, že více vláken generuje jednu odpověď.
- Tady asi použít semaphore a každé vlákno když projde semaforem, tak si ověří, že replyMessage.TextValue už něco obsahuje.

Zpracování user message na back endu už doběhne do konce.
Zbývá:
- Zprovoznit LLM connector, tzn. přidat prompt templates.
- DataspecerConnector je kinda nespolehlivý, takže si musím najít nějaký package, který zaručeně funguje, abych mohl testovat.
- Implementovat Sparql translation.
- Na front endu přidat podporu pro suggested message.
- Na back endu přidat endpoint pro suggested messages.

# 26. 7.

Todo (vyřešit někdy později):
- Když LLM vrátí nějaké itemy, tak mohou být už v databázi. To pak vyvolává konflikt když znova volám save changes, protože EF Core si myslí, že chci uložit nové itemy, ale mají identické IRI.
- LLM mapuje na itemy i když otázka nedává smysl. Např. poslal jsem jen jedno písmeno "l" a stejně jsem dostal odpověď. Možné řešení: říct, že pokud neumí namapovat slovo z otázky, tak to nesmí dát do odpovědi.
(Podobně otázka "I want to see documents" a LLM namapuje asi 4 různé entity)
- Budu muset rozšířit DataSpecificationItem model, aby Class obsahoval vazby na svoje Datatype a Object property - pro účely překlad do Sparqlu.
- Implementovat odebírání zvolených itemů na front endu.
- !Přidat zobrazení slov v původní otázce, které se namapovaly na entity.
- Přidat adresář Prompts do back end projektu. Tam dát prompty místo přímo v kódu. Přidat prompt loader class.
- Do promptů bych mohl přidat "reason" - vysvětlení, proč jaký item byl vybrán.
- Neměl by to nabízet items, které už jsou v current dataspec substructure.

# 1. 8.
Cíl:
- Zkrátit OWL soubor pomocí prefixů.

Jakým způsobem řešit PromptConstructor a ResponseProcessor?
Mám 2 možnosti:
1. LlmConnector bude uvnitř obsahovat ty 2 další podtřídy. Každý connector bude mít vlastní.
2. Defaultní prompt constructor i response processor oddělený od LLM connector. Konektory budou používat jednu z možných implementací ostatních tříd.

Možnost číslo 1 dává smysl, pokud způsob konstrukce promptu a response processing je jiný pro každý LLM. Ale response processor se váže na můj projekt a moje modelové třídy.
Je dost pravděpodobné, že různé LLM konektory mohou používat ten stejný response processor.
Podobně s prompt constructor. Já budu chtít použít stejné prompty do více LLM, takže mi stačí jedna implementace.
Z těchto důvodů oddělím prompt constructor i response processor od LlmConnector tříd.

Mohl bych vytvořit type safe systém promptovacích šablon, ale to zabere čas, který nemám. Takže se na to vykašlu.
Navíc ty šablony budu měnit a vylepšovat. Pokaždé bych musel měnit jejich kód.
- Prompty si uložím na dvou místech.
- V repozitáři projektu a tam budou pojmenované parametry.
- Stejné šablony uložím v adresáři pro back end a tam budou očíslované parametry pro metodu string.Format()

Front end by potřeboval další věci vázané k DataSpecificationItem:
- MappedWords, Expands, Reason (suggestion), Summary.
- Kromě Summary tak zbytek nedává úplně smysl ukládat přímo v DataSpecificationItem, protože se to váže buď na UserQuestion (MappedWords) nebo na ReplyMessage (Expands, Reason).

Package, které fungují:
db2ad74f-ec45-4d46-84f8-24d36fbb4200 (DCAT-...)
ca85277a-8a2b-4874-bc7a-13bd48fe798a (Záznam informačního systému nahrazující úředně ověřený podpis)

Mohl bych pokud nenajdu suggested item mapping, tak ten item vyhodit.
- Tady je trochu problém s tím, jak hledám ten mapping.
- LLM vrátí nějaký suggested item v souvislosti s celým substructure.
- Když si vezmu item v substructure a hledám mapping s user message pro reply, který stavím, tak to nemusí existovat. Ale to mapping může být s minulou zprávou v této konverzaci.
- Další problém s tím mapping je když posílám unmodified suggested message, tak potom ani nemám to mapování.
- Taky nemusí být na škodu brát v potaz itemy bez mapování. To je možná ještě zajímavější, že ten item nebyl nijak zmíněn v otázce, ale mohl být přidán do otázky.

Momentálně dělám mapování, pokud uživatel nějak ručně zadal nebo upravil zprávu.
Když přijde neupravená zpráva, tak nedělám mapování.
- To je v pořádku, ale potom nebudu mít ta slova z otázky, která se mapují na itemy.
- Možná v případě neupravené zprávy musím udělat mapování, ale ne na celou datovou specifikaci, nýbrž pouze na substructure v konverzaci.

Když přijde nemodifikovaná zpráva, tak:
1. Přidám itemy do substructure.
2. Řeknu LLM, aby namapoval slova z otázky na itemy v substructure.
- Pokud něco se nepovede namapovat, tak co? Zvolím si nějaký slovo indikující chybu mapování?
3. V tuto chvíli už každý item v substructure by měl mít mapování na slovo z otázky, takže bych pro každý suggested item měl být schopen najít mapované slovo.
4. Pokud pro suggested item nenajdu item v current substructure, tak to je možná zajímavý, protože sice není zmíněn v konverzaci, ale LLM si myslí, že se hodí.
- Přemýšlím, jak takovýto item prezentovat uživateli.
- Ostatní itemy mám jako Expands "slovo": a pak vyjmenované.
- Tady nemůžu Expands "other items".

Teď:
Dodělat mapování na substructure.
Tím zajistím, že pro suggested items -> expands budu mít vždy nějaké mapování.
Pokud suggested item expands neukazuje na item v substructure, tak vyřešit prezentaci pro uživatele.
- Že tento item nerozšiřuje přímo slova z otázky, ale pořád může rozšířit otázku.

Přidat kolečko, že chatbot přemýšlí.
Zobrazit nahoře current question.
Když namapuju nebo suggestnu item, který už je v databázi, tak asi by bylo lepší aktualizovat ten původní item s novými daty (reason, summary).
- Actually reason se pojí se "suggestion" entry, takže nemusím aktualizovat.
- Ale summary bych asi mohl.

Musím trochu upravit mapping prompt i v případě nemodifikované otázky:
- Pokud si uživatel vybere item1, který má rozšiřovat item2, ale item2 ještě není v mém substructure.
- Může se stát - LLM si může myslet, že item1 se hodí.
- Ale pokud přidám item1, tak bych měl přidat item2, abych tam měl tu vazbu ne?
Tady to vyřeším pak. Teď přidám kolečko-thinking a zobrazení current question.

Absolutně musím dodělat:
1. Sparql generation.
2. Získání reusedProperty.
3. Když dsv soubor má @base <>
4. Mazání konverzace pořád nefunguje.

# 5. 8. 2025

Zkouším modelovat třídy, atributy a vztahy OWLu.
Zkouším to cestou dědičnosti.
- Zatím se mi dědičcnost zdá zbytečně složité.

Mám třídy. Každá třída mát 0 až N atributů. Každý atribut třídy je definován triplem.
- Pokud atribut má jednoduchý typ (tzv. není objekt), tak je definován triplem, kde ten atribut je předmět.
- Např. třída T má název: ex:máNázev rdfs:domain T a ex:máNázev rdfs:range rdfs:Literal
Actually ono je to jednodušší. Existuje pouze Class a Property.
- Property může být ObjectProperty pokud spojuje Class s jiným Class.
- Property je DatatypeProperty pokud spojuje Class s jednoduchým datovým typem.
Property je atribut pro Class.

# 7. 8. 2025

Koukám na převod DSV do OWL.
Dalo by se během té operace vytvořit všechny itemy.
- Ale zpracovávám jeden triple po druhém.
- Takže musím zavést dictionary, kde key = subject node uri.
- Pak když narazím na triple, tak vyhledám iri a případně vložím nový item nebo aktualizuju nalezený item.
- To znamená, že vytvoření konverzace zabere ještě více času.

Zatím nebudu vytvářet itemy během konverze do OWLu.

Když rozšiřuju dotaz (a tedy současnou podstrukturu), tak bych měl vždycky uživateli nabídnout object nebo datatype property, který rozšiřuje třídu včetně range té property.
Příklad:
- Mám podstrukturu s 1 itemem A.
- Měl bych nabídnout properties, které mají domain A. K těm properties bych měl rovnou přidat range.
- Nabídnu properties P1, P2, P3. Každý má domain A. Pokud si uživatel vybere P1, P2, tak bych měl rovnou přidat range(P1) a range(P2).

Suggestion improvement:
Říct si o 5 nejrelevantnějších properties, které mají domain nebo range v současné struktuře.
- Na to, abych ukazoval nejbližší okolí nepotřebuju LLM.
- Ale tady využívám LLM na získání těch "nejrelevantnějších" properties.
(nápad: chatbot se učí a nejrelevantnější budou ty properties, na které se uživatelé často ptají.)

Říct si o další 4 itemy (ať už class nebo property), které sice nemusí rozšiřovat přímo současnou podstrukturu, ale jsou nějakým způsobem zajímavé.

Teď budu muset zadefinovat reprezentaci substructure.
- Potřebuju něco vhodnějšího než List<DataSpecificationItem>
- Použiju to pro generaci sparqlu a pro zobrazení uživateli.
Zadefinoval jsem znova ClassItem a PropertyItem, ale přemýšlím, že možná můžu použít DataSpecificationItem.
- Ale tam chybí seznam object properties a seznam datatype properties.
No docela se mi líbí substructure, který jsem definoval.

Jen teď musím nějak vyřešit to, že teoreticky uživatel může položit otázku, kde jsou 2 nebo i více root classes.
- Např. I want to see tournaments and sponsors.
- Můžu pak nabízet nějak properties, aby propojili ty roots, ale to až potom.

Možná "root" je trochu zavádějící.
Když uživatel položí otázku ve stylu "I want to see A, B and C, ...", tak itemy A, B, C by měly být proměnné v selectu (SELECT ?A ?B ?C WHERE ...)
- Podle mě je jedno, jestli všechny proměnné (v tomto případě A, B, C) jsou nějakým způsobem propojené nebo ne.
- Jen pro ně musím správně specifikovat WHERE clause.
- Takže místo "root" class bych to měl nazvat něco jako "select targets". A může jich být víc.
Jen je problém s tím, jak to vhodně nebo hezky zobrazit na front endu.
- Když mám jen jeden root class, tak tam začnu a postupně projdu dolů.
- Když ne, tak musím začít s nějakým class a postupně vyhazovat ty itemy, které jsem už prošel.

Měl bych se ujistit, že když rozšiřuju dotaz, tak rozšiřuju o property i range nebo domain té property.
- Tady ale narazím na ten problém, že když uživatel napíše dotaz typu "I want to see oranges and apples", tak to vlastně nevadí! Protože tam není property, který bych potřeboval přidat do substructure.
- Prostě musí platit invariant, že rozšíření property znamená, že mám její range i domain.

# 8. 8.

Když mám chci přidat item do substructure, tak potřebuju vědět, jestli se jedná o target nebo non-target.
- To asi získám jen vhodným promptem do LLM.
Takže zkusím poslat nějaké dotazy do LLM a uvidím, jestli mi to dokáže vrátit bool flag pro target.
Přemýšlím, že nechám target flag jen pro první mapování (do data spec). Pro suggestion a mapování do substructure nechám stejný - všechno dám jako non target. Protože jen rozšiřuju ne?
- Trochu bych si to zjednodušil pro tuto chvíli a podle mě to bude stačit.
- Rozšíření o více targets nechám jako future work.

Vypadá to, že templates fungují.
Teď musím jen vhodně zformátovat current context když stavím prompt v PromptConstructor.
Pak musím vhodně zpracovat data, která LLM vrací.

Musím ještě trochu vyladit prvotní mapování.
- Říkám, že pokud MappedWords je empty, tak to nemá vracet.
- Ale pokud to namapuje 2 Class a není mezi nimi žádný property, tak si nejsem jistý, jestli to dává smysl.
- Možná že to actually dává? Na začátku teda budu mít jen ty 2 Class, ale postupně to doplním o properties.

Když jde o datatype property, tak já vytvářím objekt pro ten typ jako data spec item. To je špatně.
Zdá se mi, že je moc komplikací s tím s vždycky ověřit, jestli data specification item už existuje nebo ne.
- Při zpracování data specification si všechny itemy uložím. Pak už to nebudu muset řešit.
